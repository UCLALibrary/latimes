[2017-07-11 11:49:50,422][INFO ][node                     ] [Naga] version[1.7.6], pid[630], build[c730b59/2016-11-18T15:21:16Z]
[2017-07-11 11:49:50,423][INFO ][node                     ] [Naga] initializing ...
[2017-07-11 11:49:50,490][INFO ][plugins                  ] [Naga] loaded [], sites []
[2017-07-11 11:49:50,537][INFO ][env                      ] [Naga] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [103.7gb], net total_space [186.1gb], types [hfs]
[2017-07-11 11:49:52,798][INFO ][node                     ] [Naga] initialized
[2017-07-11 11:49:52,798][INFO ][node                     ] [Naga] starting ...
[2017-07-11 11:49:52,876][INFO ][transport                ] [Naga] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/131.179.50.139:9300]}
[2017-07-11 11:49:52,899][INFO ][discovery                ] [Naga] elasticsearch/F3sorLsQScK1iirx6Z4Rvw
[2017-07-11 11:49:56,685][INFO ][cluster.service          ] [Naga] new_master [Naga][F3sorLsQScK1iirx6Z4Rvw][mbp-401][inet[/131.179.50.139:9300]], reason: zen-disco-join (elected_as_master)
[2017-07-11 11:49:56,700][INFO ][http                     ] [Naga] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/131.179.50.139:9200]}
[2017-07-11 11:49:56,700][INFO ][node                     ] [Naga] started
[2017-07-11 11:49:56,714][INFO ][gateway                  ] [Naga] recovered [0] indices into cluster_state
[2017-07-11 11:50:29,412][INFO ][cluster.metadata         ] [Naga] [latimes] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2017-07-11 11:50:29,698][INFO ][cluster.metadata         ] [Naga] [latimes] create_mapping [modelresult]
[2017-07-11 11:50:32,036][INFO ][cluster.metadata         ] [Naga] [latimes] update_mapping [modelresult] (dynamic)
[2017-07-12 11:46:25,178][INFO ][node                     ] [Genis-Vell] version[1.7.6], pid[635], build[c730b59/2016-11-18T15:21:16Z]
[2017-07-12 11:46:25,179][INFO ][node                     ] [Genis-Vell] initializing ...
[2017-07-12 11:46:25,246][INFO ][plugins                  ] [Genis-Vell] loaded [], sites []
[2017-07-12 11:46:25,291][INFO ][env                      ] [Genis-Vell] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [103.2gb], net total_space [186.1gb], types [hfs]
[2017-07-12 11:46:27,778][INFO ][node                     ] [Genis-Vell] initialized
[2017-07-12 11:46:27,778][INFO ][node                     ] [Genis-Vell] starting ...
[2017-07-12 11:46:27,915][INFO ][transport                ] [Genis-Vell] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/131.179.14.210:9300]}
[2017-07-12 11:46:27,955][INFO ][discovery                ] [Genis-Vell] elasticsearch/KAGJVJgBSTGHzeI5VZkY_Q
[2017-07-12 11:46:31,739][INFO ][cluster.service          ] [Genis-Vell] new_master [Genis-Vell][KAGJVJgBSTGHzeI5VZkY_Q][mbp-390][inet[/131.179.14.210:9300]], reason: zen-disco-join (elected_as_master)
[2017-07-12 11:46:31,757][INFO ][http                     ] [Genis-Vell] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/131.179.14.210:9200]}
[2017-07-12 11:46:31,757][INFO ][node                     ] [Genis-Vell] started
[2017-07-12 11:46:31,796][INFO ][gateway                  ] [Genis-Vell] recovered [1] indices into cluster_state
[2017-07-12 17:10:54,224][INFO ][node                     ] [Eson the Searcher] version[1.7.6], pid[3939], build[c730b59/2016-11-18T15:21:16Z]
[2017-07-12 17:10:54,224][INFO ][node                     ] [Eson the Searcher] initializing ...
[2017-07-12 17:10:54,294][INFO ][plugins                  ] [Eson the Searcher] loaded [], sites []
[2017-07-12 17:10:54,334][INFO ][env                      ] [Eson the Searcher] using [1] data paths, mounts [[/ (/dev/disk0s2)]], net usable_space [101.6gb], net total_space [186.1gb], types [hfs]
[2017-07-12 17:10:56,767][INFO ][node                     ] [Eson the Searcher] initialized
[2017-07-12 17:10:56,768][INFO ][node                     ] [Eson the Searcher] starting ...
[2017-07-12 17:10:56,842][INFO ][transport                ] [Eson the Searcher] bound_address {inet[/0:0:0:0:0:0:0:0:9300]}, publish_address {inet[/131.179.14.210:9300]}
[2017-07-12 17:10:56,862][INFO ][discovery                ] [Eson the Searcher] elasticsearch/7mTwwE8wQKGyI8fc8k7Pkg
[2017-07-12 17:11:00,651][INFO ][cluster.service          ] [Eson the Searcher] new_master [Eson the Searcher][7mTwwE8wQKGyI8fc8k7Pkg][mbp-390][inet[/131.179.14.210:9300]], reason: zen-disco-join (elected_as_master)
[2017-07-12 17:11:00,668][INFO ][http                     ] [Eson the Searcher] bound_address {inet[/0:0:0:0:0:0:0:0:9200]}, publish_address {inet[/131.179.14.210:9200]}
[2017-07-12 17:11:00,668][INFO ][node                     ] [Eson the Searcher] started
[2017-07-12 17:11:00,687][INFO ][gateway                  ] [Eson the Searcher] recovered [1] indices into cluster_state
[2017-07-12 17:11:01,084][WARN ][indices.cluster          ] [Eson the Searcher] [[latimes][0]] marking and sending shard failed due to [failed recovery]
org.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [latimes][0] failed to fetch index version after copying it over
	at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:161)
	at org.elasticsearch.index.gateway.IndexShardGatewayService$1.run(IndexShardGatewayService.java:112)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.elasticsearch.index.gateway.IndexShardGatewayRecoveryException: [latimes][0] shard allocated for local recovery (post api), should exist, but doesn't, current files: [_1e.fdt, _1e.fdx, _1e.fnm, _1e.nvd, _1e.nvm, _1e.si, _1e_Lucene410_0.dvd, _1e_Lucene410_0.dvm, _1e_Lucene41_0.doc, _1e_Lucene41_0.pos, _1e_Lucene41_0.tim, _1e_Lucene41_0.tip, _1f.cfe, _1f.cfs, _1f.si, _1g.cfe, _1g.cfs, _1g.si, _1h.cfe, _1h.cfs, _1h.si, _1i.cfe, _1i.cfs, _1i.si, segments.gen, segments_3, write.lock]
	at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:135)
	... 4 more
Caused by: java.nio.file.NoSuchFileException: /Users/cliccuser/latimes/elasticsearch-1.7.6/data/elasticsearch/nodes/0/indices/latimes/0/index/segments_4
	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102)
	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107)
	at sun.nio.fs.UnixFileSystemProvider.newFileChannel(UnixFileSystemProvider.java:177)
	at java.nio.channels.FileChannel.open(FileChannel.java:287)
	at java.nio.channels.FileChannel.open(FileChannel.java:335)
	at org.apache.lucene.store.NIOFSDirectory.openInput(NIOFSDirectory.java:81)
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)
	at org.apache.lucene.store.FilterDirectory.openInput(FilterDirectory.java:80)
	at org.elasticsearch.index.store.Store$StoreDirectory.openInput(Store.java:733)
	at org.apache.lucene.store.Directory.openChecksumInput(Directory.java:113)
	at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:341)
	at org.apache.lucene.index.SegmentInfos$1.doBody(SegmentInfos.java:462)
	at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:923)
	at org.apache.lucene.index.SegmentInfos$FindSegmentsFile.run(SegmentInfos.java:769)
	at org.apache.lucene.index.SegmentInfos.read(SegmentInfos.java:458)
	at org.elasticsearch.common.lucene.Lucene.readSegmentInfos(Lucene.java:89)
	at org.elasticsearch.index.store.Store.readSegmentsInfo(Store.java:166)
	at org.elasticsearch.index.store.Store.readLastCommittedSegmentsInfo(Store.java:152)
	at org.elasticsearch.index.gateway.local.LocalIndexShardGateway.recover(LocalIndexShardGateway.java:126)
	... 4 more
[2017-07-12 17:11:01,088][WARN ][cluster.action.shard     ] [Eson the Searcher] [latimes][0] received shard failed for [latimes][0], node[7mTwwE8wQKGyI8fc8k7Pkg], [P], s[INITIALIZING], unassigned_info[[reason=CLUSTER_RECOVERED], at[2017-07-13T00:11:00.666Z]], indexUUID [u39JFJ4WQhaLzOsAUJNf5Q], reason [shard failure [failed recovery][IndexShardGatewayRecoveryException[[latimes][0] failed to fetch index version after copying it over]; nested: IndexShardGatewayRecoveryException[[latimes][0] shard allocated for local recovery (post api), should exist, but doesn't, current files: [_1e.fdt, _1e.fdx, _1e.fnm, _1e.nvd, _1e.nvm, _1e.si, _1e_Lucene410_0.dvd, _1e_Lucene410_0.dvm, _1e_Lucene41_0.doc, _1e_Lucene41_0.pos, _1e_Lucene41_0.tim, _1e_Lucene41_0.tip, _1f.cfe, _1f.cfs, _1f.si, _1g.cfe, _1g.cfs, _1g.si, _1h.cfe, _1h.cfs, _1h.si, _1i.cfe, _1i.cfs, _1i.si, segments.gen, segments_3, write.lock]]; nested: NoSuchFileException[/Users/cliccuser/latimes/elasticsearch-1.7.6/data/elasticsearch/nodes/0/indices/latimes/0/index/segments_4]; ]]
[2017-07-12 17:12:27,611][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:12:40,215][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:12:54,841][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:13:13,448][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:13:40,077][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:14:01,722][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:14:14,347][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:14:28,980][DEBUG][action.bulk              ] [Eson the Searcher] observer: timeout notification from cluster service. timeout setting [1m], time since start [1m]
[2017-07-12 17:14:36,099][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] deleting index
[2017-07-12 17:14:36,126][WARN ][action.bulk              ] [Eson the Searcher] unexpected error during the primary phase for action [indices:data/write/bulk[s]]
java.lang.NullPointerException
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shards(TransportShardBulkAction.java:128)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.doRun(TransportShardReplicationOperationAction.java:354)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$3.onNewClusterState(TransportShardReplicationOperationAction.java:504)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.clusterChanged(ClusterStateObserver.java:177)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:498)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:204)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:167)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-07-12 17:14:36,130][WARN ][action.bulk              ] [Eson the Searcher] unexpected error during the primary phase for action [indices:data/write/bulk[s]]
java.lang.NullPointerException
	at org.elasticsearch.action.bulk.TransportShardBulkAction.shards(TransportShardBulkAction.java:128)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase.doRun(TransportShardReplicationOperationAction.java:354)
	at org.elasticsearch.common.util.concurrent.AbstractRunnable.run(AbstractRunnable.java:36)
	at org.elasticsearch.action.support.replication.TransportShardReplicationOperationAction$PrimaryPhase$3.onNewClusterState(TransportShardReplicationOperationAction.java:504)
	at org.elasticsearch.cluster.ClusterStateObserver$ObserverClusterStateListener.clusterChanged(ClusterStateObserver.java:177)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:498)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:204)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:167)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-07-12 17:14:36,169][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2017-07-12 17:14:36,253][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] create_mapping [modelresult]
[2017-07-12 17:14:36,969][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] update_mapping [modelresult] (dynamic)
[2017-07-12 17:34:02,239][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] deleting index
[2017-07-12 17:35:53,255][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] creating index, cause [api], templates [], shards [5]/[1], mappings []
[2017-07-12 17:35:53,316][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] create_mapping [modelresult]
[2017-07-12 17:35:53,972][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] update_mapping [modelresult] (dynamic)
[2017-07-12 17:38:45,802][DEBUG][action.admin.indices.mapping.put] [Eson the Searcher] failed to put mappings on indices [[latimes]], type [modelresult]
org.elasticsearch.index.mapper.MergeMappingException: Merge failed with failures {[mapper [PhotoDescription] has different index_analyzer, mapper [SubjectDescription] has different index_analyzer, mapper [text] has different index_analyzer, mapper [SubjectName] has different index_analyzer]}
	at org.elasticsearch.cluster.metadata.MetaDataMappingService$4.execute(MetaDataMappingService.java:511)
	at org.elasticsearch.cluster.service.InternalClusterService$UpdateTask.run(InternalClusterService.java:374)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.runAndClean(PrioritizedEsThreadPoolExecutor.java:204)
	at org.elasticsearch.common.util.concurrent.PrioritizedEsThreadPoolExecutor$TieBreakingPrioritizedRunnable.run(PrioritizedEsThreadPoolExecutor.java:167)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
[2017-07-12 17:38:46,448][INFO ][cluster.metadata         ] [Eson the Searcher] [latimes] update_mapping [modelresult] (dynamic)
